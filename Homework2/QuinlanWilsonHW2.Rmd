---
title: "Homework Assignment 2 PSTAT 131"
author: "Quinlan Wilson and Jack Guo (both 131)"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: pdf_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, echo=FALSE, warning=F}
library(knitr)
library(tidyverse)
library(ISLR)
library(ROCR)
library(dplyr)
library(ggplot2)
library(MASS)

# set global chunk options: images will be 7x5 inches
knitr::opts_chunk$set(
	fig.height = 5,
	fig.width = 7,
	warning = FALSE
)
options(digits = 4)

## indents are for indenting r code as formatted text
## They may need to be adjusted depending on your OS
# if your output looks odd, increase or decrease indent
indent1 = '    '
indent2 = '        '
indent3 = '            '
```

## Linear Regression

### (1.)

```{r}
glimpse(Auto)

Auto_clean <- Auto %>%
  dplyr::select(-contains("name")) %>%
  mutate(origin = as.factor(origin))

lmod <- lm(mpg ~ ., data = Auto_clean)
summary(lmod)
```

With a $0.01$ threshold we can reject the null hypothesis that there is
no linear association between mpg and displacement, weight, year, and
origin. While failing to reject that cylinders, horsepower, and
acceleration have no linear association with mpg.

### (2.)

```{r}
training_MSE <- mean((Auto$mpg - predict(lmod, Auto_clean))^2)
```

The training MSE is `r training_MSE` and we cannot calculate the test
MSE as the training set is the whole dataset so we have nothing to
compare with.

### (3.)

```{r}
car <- data.frame(
  cylinders = 4,
  displacement = 133,
  horsepower = 117,
  weight = 3250,
  acceleration = 29,
  year = 97,
  origin = factor(2) 
)


car_pre_mpg <- predict(lmod, newdata = car)
```

The gas mileage predicted for an European car with 4 cylinders,
displacement 133, horsepower of 117, weight of 3250, acceleration of 29,
built in the year 1997 is `r car_pre_mpg`.

### (4.)

```{r}
coef(lmod)
```

The difference in mpg between a Japanese car and the mpg of an American
car is 2.85323 and the difference between a European car and an American
car is 2.63000.

### (5.)

The change in mpg associated with a 30 unit increase in horsepower is
`r  coef(lmod)[4] * 30`.

```{r}
algae <- read.table("algaeBloom.txt", col.names=
                      c('season','size','speed','mxPH','mnO2','Cl','NO3','NH4',
                        'oPO4','PO4','Chla','a1','a2','a3','a4','a5','a6','a7'),
                    na = "XXXXXXX")
```

```{r}
algae.transformed <- algae %>% mutate_at(vars(4:11), funs(log(.)))
algae.transformed <- algae.transformed %>%
mutate_at(vars(4:11),funs(ifelse(is.na(.),median(.,na.rm=TRUE),.)))
# a1 == 0 means low
algae.transformed <- algae.transformed %>% mutate(a1 = factor(as.integer(a1 > 5), levels = c(0, 1)))
```

```{r}

calc_error_rate <- function(predicted.value, true.value) {
  return(mean(true.value != predicted.value))
}
```

```{r}
set.seed(1)
test.indices = sample(1:nrow(algae.transformed), 50)
algae.train=algae.transformed[-test.indices,]
algae.test=algae.transformed[test.indices,]
```

## Algae Classification using Logistic regression

```{r}
library(tidyverse)
library(ISLR)
library(ROCR)

algae <- read_table2("algaeBloom.txt", col_names=
c('season','size','speed','mxPH','mnO2','Cl','NO3','NH4',
'oPO4','PO4','Chla','a1','a2','a3','a4','a5','a6','a7'),
na="XXXXXXX")

## Take log of vars
## Fill in missing
## categorize into high/low based on a1
algae.transformed <- algae %>% mutate_at(vars(4:11), funs(log(.)))
algae.transformed <- algae.transformed %>%
mutate_at(vars(4:11),funs(ifelse(is.na(.),median(.,na.rm=TRUE),.)))
# a1 == 0 means low
algae.transformed <- algae.transformed %>% mutate(a1 = factor(as.integer(a1 > 5), levels = c(0, 1)))

## Misclassification error rate function
calc_error_rate <- function(predicted.value, true.value){
return(mean(true.value != predicted.value))
}

## Training/test sets
set.seed(1)
test.indices = sample(1:nrow(algae.transformed), 50)
algae.train=algae.transformed[-test.indices,]
algae.test=algae.transformed[test.indices,]
```

### (1.)

$z=\ln(\frac{p}{1-p})$

$e^z=\frac{p}{1-p}$

$e^z-pe^z-p=0$

$p(1-e^z)=e^z$

$p=\frac{e^z}{1-e^z}$

### (2.)

Substitute $z=\beta_0+\beta_1x_1$ into odds.

$\text{log odds}=log(\frac{p}{1-p})=z$

$odds=\frac{p}{1-p}=e^z$

$odds=e^{\beta_0+\beta_1x_1}$

$odds=e^{\beta_0+\beta_1(x_1+2)}$

$odds=e^{\beta_0+\beta_1x_1}*e^{2\beta_1}$

The odds increase by a factor of $e^{2\beta_1}$.

If $\beta_1$ is negative, $p$ approaches 0 as $x_1$ approaches $\infty$. $p$ approaches 1 as $x_1$ approaches $-\infty$.

### (3.)

```{r}
model <- glm(a1 ~ . - a2:a7, data=algae.transformed, family="binomial")
predicted <- data.frame(predicted_val=predict(model, algae.test, type="response"))
predicted_classified <- predicted %>% mutate(
  a1=as.integer(predicted_val>.5)
)
predicted_classified ## predictions of test data

## error rates
calc_error_rate(predicted_classified$a1, algae.train$a1)
calc_error_rate(predicted_classified$a1, algae.test$a1)
```

The training error is 0.573333 and the test error is 0.16.

### (4.)

```{r}
pred <- prediction(predicted_classified$a1, algae.test$a1)
perf <- performance(pred, "tpr", "fpr")
roc_data <- data.frame(
  fpr = unlist(perf@x.values),
  tpr = unlist(perf@y.values)
)
ggplot(roc_data, aes(x=fpr, y=tpr)) +
  geom_line() +
  labs(
    title="ROC Curve",
    x="False Positive Rate",
    y="True Positive Rate"
  ) 

auc <- performance(pred,"auc")
auc_value <- auc@y.values[[1]]
print(paste("AUC =", auc_value))
```

## Algae Classification using Discriminant Analysis

### (1.)

```{r}
lda_mod <- lda(a1 ~ ., data = algae.transformed, CV = T)


lda_class <- lda_mod$class

lda_error <- calc_error_rate(lda_class, algae.train$a1)
lda_post <- lda_mod$posterior

if (ncol(lda_post) == 1) {
  lda_post <- cbind("0" = 1 - lda_post, "1" = lda_post)
}

lda_probs <- lda_post[, "1"]

pred <- prediction(lda_mod$posterior[, "1"], algae.transformed$a1)
perf <- performance(pred, 'tpr', 'fpr')

plot(perf)
pred_lda <- prediction(lda_probs, algae.transformed$a1)
performance(pred_lda, "auc")@y.values[[1]]

```

### (2.)

```{r}
qda_mod <- qda(a1 ~ ., data = algae.transformed, CV = T)
qda_class <- qda_mod$class
qda_post <- qda_mod$posterior

if (ncol(qda_post) == 1) qda_post <- cbind("0" = 1 - qda_post, "1" = qda_post)

qda_probs <- qda_post[, "1"]

pred_qda <- prediction(qda_probs, algae.transformed$a1)
perf_qda <- performance(pred_qda, "tpr", "fpr")
auc_qda <- performance(pred_qda, "auc")@y.values[[1]]

plot(perf_qda)

auc_qda
```
LDA has a higher area under the ROC curve between the two models meaning it performs better at separating the two classes. LDA has the advantage of lower variance but in the case of different contrivances more bias is introduced.

## Fundamentals of the bootstrap

### (1.)

$$(1-\frac{1}{n})^n$$

### (2.)
```{r}
(1-1/1000)^1000
```

### (3.)

```{r}
n <- 1000

sample <- sample(1:n, size = n, replace = T)

missing <- n - length(unique(sample))

ratio <- missing / n 
ratio
```

## Cross-validation estimate of test error

### (1.)

```{r}
dat = subset(Smarket, select = -c(Year,Today))
dat$Direction = ifelse(dat$Direction == "Up", 1,0)

set.seed(123)
test.indices = sample(1:nrow(dat), 1250/2)
train=dat[-test.indices,]
test=dat[test.indices,]

model <- glm(Direction ~ ., data=train, family="binomial")
pred <- data.frame(predicted_val=predict(model, test, type="response"))
pred_classified <- pred %>% mutate(
  Direction=as.integer(predicted_val>.5)
)
calc_error_rate(pred_classified$Direction, test$Direction)

```

### (2.)

```{r}
do.chunk <- function(chunkid, folddef, dat, ...){
# Get training index
train = (folddef!=chunkid)
# Get training set and validation set
dat.train = dat[train, ]
dat.val = dat[-train, ]
# Train logistic regression model on training data
fit.train = glm(Direction ~ ., family = binomial, data = dat.train)
# get predicted value on the validation set
pred.val = predict(fit.train, newdata = dat.val, type = "response")
pred.val = ifelse(pred.val > .5, 1,0)
data.frame(fold = chunkid,
val.error = mean(pred.val != dat.val$Direction))
}

folddef <- sample(rep(1:10, length.out = nrow(dat)))

results <- data.frame()
for (k in 1:10) {
  results <- rbind(results, do.chunk(k, folddef, dat))
}
mean(results$val.error)
```

The average validation error for the 10-fold cross-validation was 0.4698959.